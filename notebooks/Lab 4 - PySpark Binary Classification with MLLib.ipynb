{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Basic PySpark Setup Stuff\n",
    "\n",
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the datafile\n",
    "df = spark.read.json(\"reviews_Musical_Instruments_5.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10261"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check dataset size, you know the drill\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up features -- those from Lab 3, plus a few more\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def _countWords(string):\n",
    "    if string is None:\n",
    "        return 0\n",
    "    return len(string.split())\n",
    "\n",
    "countWords = udf(_countWords)\n",
    "\n",
    "def _avgWordLength(string):\n",
    "    if string is None:\n",
    "        return 0\n",
    "    words = string.split()\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "            \n",
    "avgWordLength = udf(_avgWordLength)\n",
    "pctUpper = udf(lambda x:0 if x is None or len(x)==0 else sum(1 for y in x if y.isupper())/len(x))\n",
    "strLen = udf(lambda x:0 if x is None else len(x))\n",
    "\n",
    "wasReviewed = udf(lambda x:0 if x[1]==0 else 1)\n",
    "\n",
    "df = df.withColumn('reviewLen', countWords(df.reviewText))\n",
    "df = df.withColumn('reviewWordAvg', avgWordLength(df.reviewText))\n",
    "df = df.withColumn('pctUpper', pctUpper(df.reviewText))\n",
    "df = df.withColumn('nameLen', strLen(df.reviewerName))\n",
    "df = df.withColumn('wasReviewed', wasReviewed(df.helpful))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Point Examples:\n",
      "[LabeledPoint(0.0, [51.0,4.2745098039215685,0.0037313432835820895,48.0,5.0]), LabeledPoint(1.0, [104.0,4.240384615384615,0.016544117647058824,4.0,5.0])]\n"
     ]
    }
   ],
   "source": [
    "#See if we can use ML to predict whether anyone will react to the review\n",
    "\n",
    "#Get our dataset into the proper format\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "dataset = df.rdd.map(lambda row: LabeledPoint(row['wasReviewed'],\n",
    "                                              Vectors.dense(row['reviewLen'], \n",
    "                                                            row['reviewWordAvg'], \n",
    "                                                            row['pctUpper'],\n",
    "                                                            row['nameLen'], \n",
    "                                                            row['overall'])))\n",
    "\n",
    "# Check out some examples of how the data points look in the form accepted by MLLib\n",
    "print(\"Data Point Examples:\")\n",
    "print(dataset.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: 10261\n",
      "Training Data Size: 6915\n",
      "Test Data Size: 3346\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Size: \" + str(dataset.count()))\n",
    "\n",
    "#Split data into training and test sets\n",
    "TRAINING_DATA_RATIO = 0.67\n",
    "RANDOM_SEED = 0xdeadface\n",
    "splits = [TRAINING_DATA_RATIO, 1.0 - TRAINING_DATA_RATIO]\n",
    "training_data, test_data = dataset.randomSplit(splits, RANDOM_SEED)\n",
    "\n",
    "print(\"Training Data Size: \" + str(training_data.count()))\n",
    "print(\"Test Data Size: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train model: 1.027 seconds\n"
     ]
    }
   ],
   "source": [
    "#Train Model\n",
    "\n",
    "from pyspark.mllib.tree import RandomForest\n",
    "from time import *\n",
    "\n",
    "RF_NUM_TREES=3\n",
    "RF_MAX_DEPTH=4\n",
    "RF_MAX_BINS=8\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "model = RandomForest.trainClassifier(training_data, numClasses=2, categoricalFeaturesInfo={}, \\\n",
    "    numTrees=RF_NUM_TREES, featureSubsetStrategy=\"auto\", impurity=\"gini\", \\\n",
    "    maxDepth=RF_MAX_DEPTH, maxBins=RF_MAX_BINS, seed=RANDOM_SEED)\n",
    "\n",
    "end_time = time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Time to train model: %.3f seconds\" % elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postive Examples: 3465 Negative Examples: 6796\n",
      "Most Common Class Baseline Error: 0.3376863853425592\n",
      "Test Error: 0.28302450687387926\n",
      "\n",
      "Learned classification forest model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 0 <= 103.0)\n",
      "     If (feature 0 <= 71.0)\n",
      "      If (feature 4 <= 2.0)\n",
      "       If (feature 4 <= 1.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 4 > 1.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 4 > 2.0)\n",
      "       If (feature 4 <= 3.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 4 > 3.0)\n",
      "        Predict: 0.0\n",
      "     Else (feature 0 > 71.0)\n",
      "      If (feature 2 <= 0.031598513011152414)\n",
      "       If (feature 1 <= 4.579710144927536)\n",
      "        Predict: 0.0\n",
      "       Else (feature 1 > 4.579710144927536)\n",
      "        Predict: 0.0\n",
      "      Else (feature 2 > 0.031598513011152414)\n",
      "       If (feature 2 <= 0.0398406374501992)\n",
      "        Predict: 1.0\n",
      "       Else (feature 2 > 0.0398406374501992)\n",
      "        Predict: 0.0\n",
      "    Else (feature 0 > 103.0)\n",
      "     If (feature 0 <= 168.0)\n",
      "      If (feature 1 <= 4.329268292682927)\n",
      "       If (feature 1 <= 4.213675213675214)\n",
      "        Predict: 0.0\n",
      "       Else (feature 1 > 4.213675213675214)\n",
      "        Predict: 0.0\n",
      "      Else (feature 1 > 4.329268292682927)\n",
      "       If (feature 4 <= 3.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 4 > 3.0)\n",
      "        Predict: 1.0\n",
      "     Else (feature 0 > 168.0)\n",
      "      If (feature 2 <= 0.022919179734620022)\n",
      "       If (feature 1 <= 4.213675213675214)\n",
      "        Predict: 0.0\n",
      "       Else (feature 1 > 4.213675213675214)\n",
      "        Predict: 1.0\n",
      "      Else (feature 2 > 0.022919179734620022)\n",
      "       If (feature 3 <= 9.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 3 > 9.0)\n",
      "        Predict: 1.0\n",
      "  Tree 1:\n",
      "    If (feature 0 <= 103.0)\n",
      "     If (feature 4 <= 2.0)\n",
      "      If (feature 3 <= 13.0)\n",
      "       If (feature 0 <= 53.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 0 > 53.0)\n",
      "        Predict: 1.0\n",
      "      Else (feature 3 > 13.0)\n",
      "       If (feature 0 <= 53.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 0 > 53.0)\n",
      "        Predict: 1.0\n",
      "     Else (feature 4 > 2.0)\n",
      "      If (feature 0 <= 53.0)\n",
      "       If (feature 0 <= 40.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 0 > 40.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 0 > 53.0)\n",
      "       If (feature 1 <= 4.096385542168675)\n",
      "        Predict: 0.0\n",
      "       Else (feature 1 > 4.096385542168675)\n",
      "        Predict: 0.0\n",
      "    Else (feature 0 > 103.0)\n",
      "     If (feature 2 <= 0.022919179734620022)\n",
      "      If (feature 0 <= 168.0)\n",
      "       If (feature 1 <= 4.579710144927536)\n",
      "        Predict: 0.0\n",
      "       Else (feature 1 > 4.579710144927536)\n",
      "        Predict: 1.0\n",
      "      Else (feature 0 > 168.0)\n",
      "       If (feature 1 <= 4.788461538461538)\n",
      "        Predict: 1.0\n",
      "       Else (feature 1 > 4.788461538461538)\n",
      "        Predict: 1.0\n",
      "     Else (feature 2 > 0.022919179734620022)\n",
      "      If (feature 0 <= 168.0)\n",
      "       If (feature 4 <= 2.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 4 > 2.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 0 > 168.0)\n",
      "       If (feature 1 <= 4.579710144927536)\n",
      "        Predict: 1.0\n",
      "       Else (feature 1 > 4.579710144927536)\n",
      "        Predict: 1.0\n",
      "  Tree 2:\n",
      "    If (feature 4 <= 3.0)\n",
      "     If (feature 1 <= 4.329268292682927)\n",
      "      If (feature 0 <= 53.0)\n",
      "       If (feature 2 <= 0.0164021164021164)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 0.0164021164021164)\n",
      "        Predict: 0.0\n",
      "      Else (feature 0 > 53.0)\n",
      "       If (feature 4 <= 1.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 4 > 1.0)\n",
      "        Predict: 0.0\n",
      "     Else (feature 1 > 4.329268292682927)\n",
      "      If (feature 0 <= 103.0)\n",
      "       If (feature 3 <= 16.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 3 > 16.0)\n",
      "        Predict: 1.0\n",
      "      Else (feature 0 > 103.0)\n",
      "       If (feature 1 <= 4.788461538461538)\n",
      "        Predict: 1.0\n",
      "       Else (feature 1 > 4.788461538461538)\n",
      "        Predict: 1.0\n",
      "    Else (feature 4 > 3.0)\n",
      "     If (feature 0 <= 71.0)\n",
      "      If (feature 0 <= 40.0)\n",
      "       If (feature 0 <= 23.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 0 > 23.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 0 > 40.0)\n",
      "       If (feature 2 <= 0.0398406374501992)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 0.0398406374501992)\n",
      "        Predict: 0.0\n",
      "     Else (feature 0 > 71.0)\n",
      "      If (feature 0 <= 168.0)\n",
      "       If (feature 0 <= 103.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 0 > 103.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 0 > 168.0)\n",
      "       If (feature 1 <= 4.096385542168675)\n",
      "        Predict: 0.0\n",
      "       Else (feature 1 > 4.096385542168675)\n",
      "        Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get Baseline for performance\n",
    "positives = dataset.filter(lambda point: point.label == 1).count()\n",
    "negatives = dataset.count() - positives\n",
    "print(\"Postive Examples: \" + str(positives) + \" Negative Examples: \" + str(negatives))\n",
    "print(\"Most Common Class Baseline Error: \" + str(min(positives, negatives) / dataset.count()))\n",
    "\n",
    "#Compare our model's prediction accuracy to the baseline\n",
    "predictions = model.predict(test_data.map(lambda x: x.features))\n",
    "labels_and_predictions = test_data.map(lambda lp: lp.label).zip(predictions)\n",
    "test_err = labels_and_predictions.filter(\n",
    "    lambda lp: lp[0] != lp[1]).count() / float(test_data.count())\n",
    "print('Test Error: ' + str(test_err))\n",
    "print()\n",
    "print()\n",
    "#Check out the model that was learned\n",
    "print('Learned classification forest model:')\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Challenge! \n",
    "#\n",
    "# Can you improve the performance of the classifier?\n",
    "# Perhaps consider using some of the features you \n",
    "# came up with in the last lab exercise. Alternatively,\n",
    "# you could make up some new features that you feel are\n",
    "# particularly suited to this problem. Also, you could\n",
    "# try adjusting the parameters of the learning algorithm,\n",
    "# or even applying a different algorithm, such as SVMs.\n",
    "#\n",
    "#####################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
