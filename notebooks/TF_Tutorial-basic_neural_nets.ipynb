{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Neural Networks with TF\n",
    "\n",
    "Constructing a neural network in TF low level python API allows you to create your own layers as functions to be combined in flexible ways. \n",
    "\n",
    "\n",
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianmuellerklein/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normalize(data):\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    return (data - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "2     10000     1.0           0     0     ...          6         770   \n",
       "3      5000     1.0           0     0     ...          7        1050   \n",
       "4      8080     1.0           0     0     ...          8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_dat = pd.read_csv('Housing_data/kc_house_data.csv')\n",
    "house_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19451, 18)\n",
      "(19451, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the data into numpy arrays\n",
    "housing_features = house_dat[house_dat.columns.difference(['id', 'price', 'date', 'zipcode'])].values\n",
    "housing_targets = house_dat.price.values\n",
    "housing_targets = housing_targets / np.max(housing_targets)\n",
    "\n",
    "n, f_dim = housing_features.shape\n",
    "\n",
    "# normalize the features\n",
    "housing_features= normalize(housing_features)\n",
    "\n",
    "# add bias\n",
    "housing_features = np.c_[np.ones((n, 1)), housing_features]\n",
    "\n",
    "# reshape targets to TF expectation\n",
    "housing_targets = np.expand_dims(housing_targets, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing_features,\n",
    "                                                    housing_targets,\n",
    "                                                    test_size=0.1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Neural Network Hyperparameters\n",
    "\n",
    "LR, EPOCHS, BATCHSIZE, and n_hidden are all parameters that you can play with to acheive the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "EPOCHS = 200\n",
    "BATCHSIZE = 32\n",
    "n_inputs = 8\n",
    "n_hidden = 32\n",
    "n_output = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be training this network with mini-batch gradient descent we need to set up tensorflow placeholders for our input and target data. The place holders serve as buckets in our graph that we can place data into during training. We need only to define the shape of the data with respect to the feature dimensions. The `None` serves as a wildcard for the batchsize, having `None` there allows us to use any batch size that we choose during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, f_dim+1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Build your own generic dense layer function. \n",
    "\n",
    "The following code block should create a dense neural network layer. First start with a named scope, this allows the arbitrary blocks/layers to be stacked up with unique names in the TF graph. Then initialize the weights of the layers using the [He normal initialization method](https://arxiv.org/pdf/1502.01852.pdf).\n",
    "\n",
    "```python\n",
    "stddev = 2 / np.sqrt(n_inputs + n_units)\n",
    "init = tf.truncated_normal((n_inputs, n_units), stddev=stddev)\n",
    "```\n",
    "\n",
    "Then we set up the weight matrix and bias vector.\n",
    "\n",
    "Finall, we compute the linear combination of the weight vector, input data and bais vector. Passing that through an activation function if that were provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_layer(X, n_units, name, activation=None):\n",
    "    '''\n",
    "    Sets up a hidden layer to be used to build a multilayer perceptron. \n",
    "    \n",
    "    Initializes the weights of the neurons using a normal distribution with\n",
    "    standard deviation equal to 2 / sqrt(input_dimension + number_neurons)\n",
    "    \n",
    "    Parameters:\n",
    "    X: input data for the layer\n",
    "    n_units: number of neurons to use in the layer\n",
    "    name: the name of the scope to be used with this layer\n",
    "    activation: the tensorflow nonlinearity to be used for each neuron\n",
    "    \n",
    "    Returns:\n",
    "    Tensorflow graph description representing the constructed layer\n",
    "    '''\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs + n_units)\n",
    "        init = tf.truncated_normal((n_inputs, n_units), stddev=stddev)\n",
    "        W = tf.Variable(init, name='hidden_weights')\n",
    "        b = tf.Variable(tf.zeros([n_units]), name='bias')\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a neural network from this layer definition is fairly straight forward now. We essentially just create a new named scope and stack two of our newly created layers together with the desired parameters. If we wanted more layers we would simply just add more to the center of our network definition.\n",
    "\n",
    "We will also create TF scopes for the loss and SGD functions, a slight twist on what we did before but the functionality is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the network using the hidden layer function\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden = dense_layer(X, n_hidden, name='hidden_layer', activation=tf.nn.relu)\n",
    "    y_pred = dense_layer(hidden, 1, name='output')\n",
    "    \n",
    "with tf.name_scope('loss'):\n",
    "    error = y_pred - y\n",
    "    loss = tf.reduce_mean(tf.square(error), name='mse')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(LR).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network using mini-batch gradient descent. We will slice up our training data into batches of size `BATCHSIZE` and feed each batch into the network in succession. Just like we did with the linear model in the previous notebook, but with smaller portions of the dataset for each step rather than the whole thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Current loss: 0.743567 Test loss: 0.78923\n",
      "Epoch: 10 Current loss: 0.00223349 Test loss: 0.00238441\n",
      "Epoch: 20 Current loss: 0.00108781 Test loss: 0.0011202\n",
      "Epoch: 30 Current loss: 0.000794609 Test loss: 0.000786982\n",
      "Epoch: 40 Current loss: 0.000689085 Test loss: 0.000662857\n",
      "Epoch: 50 Current loss: 0.000644304 Test loss: 0.000608128\n",
      "Epoch: 60 Current loss: 0.000622246 Test loss: 0.000580562\n",
      "Epoch: 70 Current loss: 0.000609638 Test loss: 0.0005651\n",
      "Epoch: 80 Current loss: 0.000601261 Test loss: 0.000555491\n",
      "Epoch: 90 Current loss: 0.000594991 Test loss: 0.000548899\n",
      "Epoch: 100 Current loss: 0.000589938 Test loss: 0.000544022\n",
      "Epoch: 110 Current loss: 0.00058569 Test loss: 0.000540157\n",
      "Epoch: 120 Current loss: 0.000582037 Test loss: 0.000536957\n",
      "Epoch: 130 Current loss: 0.000578789 Test loss: 0.000534215\n",
      "Epoch: 140 Current loss: 0.000575857 Test loss: 0.000531789\n",
      "Epoch: 150 Current loss: 0.000573154 Test loss: 0.000529614\n",
      "Epoch: 160 Current loss: 0.000570651 Test loss: 0.000527666\n",
      "Epoch: 170 Current loss: 0.000568343 Test loss: 0.000525885\n",
      "Epoch: 180 Current loss: 0.000566207 Test loss: 0.000524253\n",
      "Epoch: 190 Current loss: 0.000564202 Test loss: 0.000522735\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "losses = []\n",
    "n_samples = X_train.shape[0]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for e in range(EPOCHS):\n",
    "        if e % 10 == 0:\n",
    "            print(\"Epoch:\", e, \n",
    "                  \"Current loss:\", \n",
    "                  sess.run(loss, feed_dict={X: X_train, y: y_train}), \n",
    "                  \"Test loss:\",\n",
    "                  sess.run(loss, feed_dict={X: X_test, y: y_test}))\n",
    "            \n",
    "        for i in range((n_samples + BATCHSIZE - 1) // BATCHSIZE):\n",
    "            sl = slice(i * BATCHSIZE, (i+1) * BATCHSIZE)\n",
    "            X_b = X_train[sl]\n",
    "            y_b = y_train[sl]\n",
    "            sess.run(train_step, feed_dict={X: X_b, y: y_b})\n",
    "            losses.append(sess.run(loss, feed_dict={X: X_b, y: y_b}))\n",
    "        \n",
    "    save_path = saver.save(sess, '/tmp/mlp_regression.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load the saved model and make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/mlp_regression.ckpt\n",
      "0.000521307\n"
     ]
    }
   ],
   "source": [
    "# best weight values are saved in the checkpoint\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '/tmp/mlp_regression.ckpt')\n",
    "    preds = sess.run(y_pred, feed_dict={X: X_test})\n",
    "    print(sess.run(loss, feed_dict={X: X_test, y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did better than the simple linear regression from the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMg4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125437518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, preds)\n",
    "ax.plot([y_test.min(), y_test.max()], \n",
    "        [y_test.min(), y_test.max()], '--', lw=3, color='r')\n",
    "ax.set_xlabel('True Value')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
